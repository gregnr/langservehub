{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16f2c32e",
   "metadata": {},
   "source": [
    "## Document Loading\n",
    "\n",
    "Load a blog post on agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9fadce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "text = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4086be03",
   "metadata": {},
   "source": [
    "## Extraction Template\n",
    "\n",
    "\n",
    "Get langserve and create app:\n",
    "```\n",
    "pip install < to add > \n",
    "langchain serve new my-app\n",
    "cd my-app\n",
    "```\n",
    "\n",
    "Add template and start server:\n",
    "```\n",
    "langchain serve add extraction-summary\n",
    "```\n",
    "\n",
    "Start server:\n",
    "```\n",
    "langchain serve install\n",
    "poetry run poe start\n",
    "```\n",
    "\n",
    "Note, we can now look at the endpoints:\n",
    "\n",
    "http://127.0.0.1:8000/docs#\n",
    "\n",
    "And look specifically at our loaded template:\n",
    "\n",
    "http://127.0.0.1:8000/docs#/default/invoke_extraction_summary_invoke_post\n",
    " \n",
    "We can also use remote runnable to call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed507784",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langserve.client import RemoteRunnable\n",
    "extraction_model = RemoteRunnable('http://localhost:8000/extraction-summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68046695",
   "metadata": {},
   "source": [
    "The function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dace748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'name': 'Overview', 'arguments': '{\\n  \"summary\": \"This article discusses the concept of building autonomous agents powered by LLM (large language model). It explores the key components of such agents, including planning, memory, and tool use. It also presents case studies and challenges associated with building LLM-powered agents.\",\\n  \"language\": \"English\",\\n  \"keywords\": \"LLM, autonomous agents, planning, memory, tool use, case studies, challenges\"\\n}'}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_model.invoke(text[0].page_content[0:1500])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langserve",
   "language": "python",
   "name": "langserve"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
